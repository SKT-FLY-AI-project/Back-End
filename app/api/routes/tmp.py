# from fastapi import FastAPI, HTTPException, Body
# from fastapi.middleware.cors import CORSMiddleware
# from pydantic import BaseModel
# from typing import List, Dict, Optional
# import anthropic
# import os
# from dotenv import load_dotenv

# # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# load_dotenv()

# # Anthropic API í‚¤ ê°€ì ¸ì˜¤ê¸°
# ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
# if not ANTHROPIC_API_KEY:
#     raise ValueError("ANTHROPIC_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# # Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

# app = FastAPI()

# # CORS ì„¤ì •
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],  # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ëª¨ë“  ì˜¤ë¦¬ì§„ í—ˆìš©, í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œí•˜ì„¸ìš”
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# class ChatMessage(BaseModel):
#     message: str
#     conversation_history: Optional[List[Dict[str, str]]] = None

# # ëŒ€í™” ì„¸ì…˜ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
# conversation_sessions = {}

# @app.post("/chat/bot")
# async def chat_with_bot(chat_data: ChatMessage = Body(...)):
#     try:
#         message = chat_data.message
        
#         # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ì „ì†¡í•œ ê²½ìš° ì‚¬ìš©
#         conversation_history = chat_data.conversation_history or []
        
#         # Anthropic ë©”ì‹œì§€ í¬ë§·ìœ¼ë¡œ ë³€í™˜
#         messages = []
        
#         # ëŒ€í™” ê¸°ë¡ì´ ìˆìœ¼ë©´ ë©”ì‹œì§€ì— ì¶”ê°€
#         for item in conversation_history:
#             if "question" in item and item["question"]:
#                 messages.append({"role": "user", "content": item["question"]})
#             if "response" in item and item["response"]:
#                 messages.append({"role": "assistant", "content": item["response"]})
        
#         # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
#         messages.append({"role": "user", "content": message})
        
#         # ëŒ€í™” ê¸°ë¡ì´ ë¹„ì–´ìˆìœ¼ë©´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
#         if not messages:
#             messages.insert(0, {
#                 "role": "system",
#                 "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”."
#             })
        
#         # Claude API í˜¸ì¶œ
#         response = client.messages.create(
#             model="claude-3-5-sonnet-20241022",  # ì›í•˜ëŠ” ëª¨ë¸ë¡œ ë³€ê²½ ê°€ëŠ¥
#             max_tokens=1000,
#             messages=messages
#         )
        
#         # ì‘ë‹µ ë°˜í™˜
#         return {"response": response.content[0].text}
    
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"Error: {str(e)}")

# # ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ (ì„ íƒì‚¬í•­)
# class SessionRequest(BaseModel):
#     session_id: str

# @app.post("/chat/create_session")
# async def create_session(request: SessionRequest):
#     session_id = request.session_id
#     if session_id not in conversation_sessions:
#         conversation_sessions[session_id] = []
#     return {"session_id": session_id, "message": "ì„¸ì…˜ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."}

# @app.post("/chat/end_session")
# async def end_session(request: SessionRequest):
#     session_id = request.session_id
#     if session_id in conversation_sessions:
#         del conversation_sessions[session_id]
#     return {"message": "ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}

# # ì„œë²„ ì‹¤í–‰ìš© ì½”ë“œ
# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run(app, host="0.0.0.0", port=8000)
    
    
    
# # def answer_user_question(image_title, vlm_description, dominant_colors, edges):
# #     """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ LLMì„ í†µí•´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
# #     while True:
# #         user_question = input("\nâ“ ì¶”ê°€ ì§ˆë¬¸ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
# #         if user_question.lower() == "exit":
# #             print("ğŸ“¢ ì§ˆë¬¸ ëª¨ë“œ ì¢…ë£Œ.")
# #             break
        
# #         # LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
# #         prompt = f"""
# #         ì‚¬ìš©ìëŠ” '{image_title}' ì‘í’ˆì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.
# #         ì‘í’ˆ ì„¤ëª…: {vlm_description}
# #         ì£¼ìš” ìƒ‰ìƒ: {dominant_colors}
# #         ì—£ì§€ ê°ì§€ ê²°ê³¼: {edges}
        
# #         ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{user_question}"
        
# #         ìœ„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ìœ ìµí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
# #         """
        
# #         # LLMì„ ì´ìš©í•œ ë‹µë³€ ìƒì„±
# #         answer = generate_rich_description(image_title, prompt, dominant_colors, edges)
# #         print(answer)

# #         # ìŒì„± ë³€í™˜
# #         text_to_speech(answer, output_file=f"answer_{image_title}.mp3")