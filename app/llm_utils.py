########################### SETP 2 : LLM #####################################

import openai
import os
import requests
import json
from dotenv import load_dotenv
from groq import Groq
import re
import torch
import numpy as np
from PIL import Image
from transformers import AutoModelForVision2Seq, AutoProcessor
from qwen_vl_utils import process_vision_info

from app.opencv_utils import get_color_name
from langchain.prompts import PromptTemplate


# Hugging Face ëª¨ë¸ ìºì‹œ ê²½ë¡œ ì„¤ì •
os.environ['HF_HOME'] = "D:/huggingface_models"
client = Groq(api_key="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")

# ëª¨ë¸ ì •ë³´ ì„¤ì •
model_name = "Qwen/Qwen2.5-VL-3B-Instruct"
device = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… ëª¨ë¸ ë¡œë“œ (FP16ìœ¼ë¡œ ë³€ê²½)
model = AutoModelForVision2Seq.from_pretrained(
    model_name,
    torch_dtype=torch.float16,  # âœ… FP16 ì‚¬ìš© (BF16 ë¬¸ì œ ë°©ì§€)
    device_map="auto",
    max_memory={0: "10GiB", "cpu": "30GiB"}
)

processor = AutoProcessor.from_pretrained(model_name)

import re

# ì •ì œ ì½”ë“œ
def clean_and_restore_spacing(text):
    """
    Qwen2.5-VLì˜ ì¶œë ¥ì—ì„œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  ë„ì–´ì“°ê¸°ë¥¼ ë³µì›í•˜ëŠ” í•¨ìˆ˜.
    """
    # âœ… 1. "ì´ ê·¸ë¦¼ì€" ë˜ëŠ” "ì´ ì¥ë©´ì€"ì´ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ ëª¨ë“  í…ìŠ¤íŠ¸ ì œê±°
    text = re.sub(r".*?(ì´ ê·¸ë¦¼ì€|ì´ ì¥ë©´ì€)", r"\1", text, flags=re.IGNORECASE | re.DOTALL)

    # âœ… 2. "ì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ~ ì„¤ëª…í•˜ì„¸ìš”" ê°™ì€ í”„ë¡¬í”„íŠ¸ ì œê±°
    prompt_text = "ì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì¥ë©´, ìƒ‰ì±„, êµ¬ë„, ë¶„ìœ„ê¸°, ì£¼ìš” íŠ¹ì§•ì„ ì„¤ëª…í•˜ì„¸ìš”."
    text = text.replace(prompt_text, "").strip()

    # âœ… 3. ì—°ì†ëœ ê³µë°±ì„ í•œ ê°œì˜ ê³µë°±ìœ¼ë¡œ ë³€ê²½
    text = re.sub(r"\s+", " ", text).strip()

    # âœ… 4. í•œê¸€ê³¼ ì˜ì–´/ìˆ«ì ì‚¬ì´ì— ê³µë°± ì¶”ê°€ (ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸° ë³µì›)
    text = re.sub(r"([ê°€-í£])([a-zA-Z0-9])", r"\1 \2", text)  # í•œê¸€ + ì˜ì–´/ìˆ«ì
    text = re.sub(r"([a-zA-Z0-9])([ê°€-í£])", r"\1 \2", text)  # ì˜ì–´/ìˆ«ì + í•œê¸€

    return text

# ì´ë¯¸ì§€ ì„¤ëª… VLM
def generate_vlm_description_qwen(image_path):
    # âœ… ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì§• (512x512)
    image = Image.open(image_path).convert("RGB")
    image = image.resize((512, 512)) # ì¼ë‹¨ì€ í¬ê¸° ì •ê·œí™” í–ˆëŠ”ë° ì¶”í›„ ìˆ˜ì • í•„ìš”.
    
    prompt = "ì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì¥ë©´, ìƒ‰ì±„, êµ¬ë„, ë¶„ìœ„ê¸°, ì£¼ìš” íŠ¹ì§•ì„ ì„¤ëª…í•˜ì„¸ìš”."

    # âœ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (apply_chat_template ì‚¬ìš©)
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {"type": "text", "text": prompt},
            ],
        }
    ]

    # âœ… Chat Template ì ìš© (Qwen2.5-VLì—ì„œëŠ” í•„ìˆ˜)
    text_input = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) # ì´ê±° ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì•ˆëŒì•„ê°‘ë‹ˆë‹¤ ì§„ì§œ ì¤‘ìš”í•¨

    # âœ… ëª¨ë¸ ì…ë ¥ ë³€í™˜
    inputs = processor(
        text=[text_input],  # âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì…ë ¥
        images=image,
        return_tensors="pt",
        padding=True,
    ).to(model.device)

    # âœ… ëª¨ë¸ ì‹¤í–‰ (í† í° ìˆ˜ ìµœì í™”)
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=256) # 128ë¡œ í•˜ë‹ˆê¹Œ ì¢€ ì§¤ë¦¬ëŠ”ë“¯;

    # âœ… ê²°ê³¼ ë””ì½”ë”© ë° ì„¸ë¡œ ì¶œë ¥ ë¬¸ì œ í•´ê²°
    description = processor.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]
    description = clean_and_restore_spacing(description)

    return description


########################### STEP 3 : í…ìŠ¤íŠ¸ ìƒì„± ë° ìŒì„± ë³€í™˜ ###############################
from gtts import gTTS

def generate_rich_description(title, vlm_desc, dominant_colors, edges):
    """
    AIê°€ ìƒì„±í•œ ê¸°ë³¸ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ë³´ë‹¤ í’ë¶€í•œ ê·¸ë¦¼ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    """
    color_names = [get_color_name(c) for c in dominant_colors[:5]]
    dominant_colors_text = ", ".join(color_names)
    edges_detected = "ëª…í™•íˆ íƒì§€ë¨" if np.sum(edges) > 10000 else "ë¶ˆëª…í™•í•˜ê²Œ íƒì§€ë¨"

    prompt_template = PromptTemplate(
        input_variables=["title", "vlm_desc", "dominant_colors", "edges_detected"],
        template=f"""
        ë‹¹ì‹ ì€ ê·¸ë¦¼ ì„¤ëª… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
        ë‹¤ìŒ ê·¸ë¦¼ì— ëŒ€í•´ ìƒì„¸í•œ ì„¤ëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        ì‹œê°ì¥ì• ì¸ì—ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ìì„¸í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        **ë‹¨, 200ì ~ 500ì ì‚¬ì´ì˜ ê¸¸ì´ë¡œë§Œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤!**

        - **ì œëª©:** "{title}"  
        - **VLM ê¸°ë°˜ ê¸°ë³¸ ì„¤ëª…:** "{vlm_desc}"   

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¸ë¦¼ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.  
        ì‘í’ˆì˜ ë¶„ìœ„ê¸°, ìƒ‰ì±„, êµ¬ë„, í‘œí˜„ ê¸°ë²• ë“±ì„ ë¶„ì„í•˜ê³ ,  
        ê°€ëŠ¥í•˜ë‹¤ë©´ ì—­ì‚¬ì , ì˜ˆìˆ ì  ë°°ê²½ë„ í•¨ê»˜ ì œê³µí•´ ì£¼ì„¸ìš”.  
        ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€(ê°€-í£)ë§Œ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**  
        ì˜ì–´, ìˆ«ì, íŠ¹ìˆ˜ë¬¸ìëŠ” í¬í•¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  
        """
    )

    formatted_prompt = prompt_template.format(
        title=title,
        vlm_desc=vlm_desc,
        dominant_colors=dominant_colors_text,
        edges_detected=edges_detected
    )

    completion = client.chat.completions.create(
        model="qwen-2.5-coder-32b",
        messages=[{"role": "user", "content": formatted_prompt}],
        temperature=0.5,
        max_tokens=1024,
        top_p=0.95
    )

    return completion.choices[0].message.content.strip()

def text_to_speech(text, output_file="output.mp3"):
    """
    ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„± íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    """
    try:
        if "<think>" in text:
            text = text.split("</think>")[-1].strip()
        tts = gTTS(text=text, lang='ko')
        tts.save(output_file)
        print(f"ìŒì„± íŒŒì¼ì´ '{output_file}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        os.system(f"start {output_file}")  # Windows (macOS: open, Linux: xdg-open)
    except Exception as e:
        print(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


########################### STEP 4 : ì§ˆë¬¸ ë‹µë³€ ëª¨ë“œë¥¼ ì§„í–‰í•˜ëŠ” í•¨ìˆ˜ ###############################        
def answer_user_question(image_title, vlm_description, dominant_colors, edges):
    """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ LLMì„ í†µí•´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    while True:
        user_question = input("\nâ“ ì¶”ê°€ ì§ˆë¬¸ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
        if user_question.lower() == "exit":
            print("ğŸ“¢ ì§ˆë¬¸ ëª¨ë“œ ì¢…ë£Œ.")
            break
        
        # LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ì‚¬ìš©ìëŠ” '{image_title}' ì‘í’ˆì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        ì‘í’ˆ ì„¤ëª…: {vlm_description}
        ì£¼ìš” ìƒ‰ìƒ: {dominant_colors}
        ì—£ì§€ ê°ì§€ ê²°ê³¼: {edges}
        
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{user_question}"
        
        ìœ„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ìœ ìµí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
        """
        
        # LLMì„ ì´ìš©í•œ ë‹µë³€ ìƒì„±
        answer = generate_rich_description(image_title, prompt, dominant_colors, edges)
        print("\nğŸ’¬ AIì˜ ë‹µë³€:")
        print(answer)

        # ìŒì„± ë³€í™˜
        text_to_speech(answer, output_file=f"answer_{image_title}.mp3")
        
########################### STEP 5 : ì§ˆë¬¸ ë‹µë³€ ëª¨ë“œë¥¼ ì§„í–‰í•˜ëŠ” í•¨ìˆ˜ ###############################
def start_vts_conversation(image_title, vlm_description): # ì•„ì§ RAGëŠ” ì§„í–‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
    """VTS ë°©ì‹ì˜ ê°ìƒ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ëŠ” í•¨ìˆ˜"""
    print("\nğŸ–¼ï¸ VTS ê°ìƒ ëª¨ë“œ ì‹œì‘!")
    
    while True:
        # LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ì‚¬ìš©ìê°€ '{image_title}' ì‘í’ˆì„ ê°ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.
        ì‘í’ˆ ì„¤ëª…: {vlm_description}

        ì‚¬ìš©ìê°€ ë” ê¹Šì´ ê°ìƒí•  ìˆ˜ ìˆë„ë¡ VTS(Visual Thinking Strategies) ë°©ì‹ì˜ ì§ˆë¬¸ì„ í•˜ë‚˜ì”© ì œê³µí•˜ì„¸ìš”.
        ì´ì „ ì§ˆë¬¸ê³¼ ì—°ê´€ë˜ë„ë¡ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ì œì‹œí•˜ê³ , ê°ìƒìê°€ ìƒê°ì„ í™•ì¥í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ì„¸ìš”.
        """
        
        # LLMì„ ì´ìš©í•œ VTS ì§ˆë¬¸ ìƒì„±
        vts_question = generate_rich_description(image_title, prompt, [], [])
        
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        user_response = input(f"\nğŸ¨ {vts_question} (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
        if user_response.lower() == "exit":
            print("ğŸ“¢ VTS ê°ìƒ ëª¨ë“œ ì¢…ë£Œ.")
            break
