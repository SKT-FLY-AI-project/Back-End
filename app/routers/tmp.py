import openai
import os
import requests
import cv2
import json
from dotenv import load_dotenv
from groq import Groq
import re
import torch
import numpy as np
from PIL import Image
from transformers import AutoModelForVision2Seq, AutoProcessor
from qwen_vl_utils import process_vision_info
from PIL import Image

# ìˆ˜ì œ ë²ˆì—­ í•¨ìˆ˜
from .data import translate

#from app.models.one_imageDetection.opencv_utils import get_color_name
from one_imageDetection.opencv_utils import get_color_name
from langchain.prompts import PromptTemplate

import random
from sentence_transformers import SentenceTransformer, util

# Hugging Face ëª¨ë¸ ìºì‹œ ê²½ë¡œ ì„¤ì •
os.environ['HF_HOME'] = "D:/huggingface_models"
client = Groq(api_key="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")

# ëª¨ë¸ ì •ë³´ ì„¤ì •
model_name = "Qwen/Qwen2.5-VL-3B-Instruct"
dtype = torch.float16 if torch.cuda.is_available() else torch.float32
device = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… ëª¨ë¸ ë¡œë“œ (FP16ìœ¼ë¡œ ë³€ê²½)
model = AutoModelForVision2Seq.from_pretrained(
    model_name,
    torch_dtype=dtype,  # âœ… GPUëŠ” FP16 ì‚¬ìš©, CPUëŠ” FP32 ì‚¬ìš©
    device_map=device, # ì›ë˜ëŠ” auto. CPU ì“¸ê±°ë©´ cpuë¡œ ë°”ê¿”ì•¼í•¨.
    max_memory={0: "10GiB", "cpu": "30GiB"}
)

processor = AutoProcessor.from_pretrained(model_name)

########################## SETP 1 : ëŒ€í™” ê²€ì¦ í•¨ìˆ˜ ##############################
# ë¯¸ìˆ  ì •ë³´ RAGì—ì„œ ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ê²€ì¦ìš©) : art_RAG_questions.json

def load_art_database():
    """ì˜ˆìˆ  DBë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜"""
    current_dir = os.path.dirname(os.path.abspath(__file__))  
    file_path = os.path.join(current_dir, "data", "labels_with_image_paths.json")
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"âŒ ì˜ˆìˆ  DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)
    
# ì‘í’ˆ ì •ë³´ ê²€ìƒ‰ í•¨ìˆ˜
def search_artwork_by_title(title):
    """
    ì‘í’ˆ ì œëª©ì„ ê¸°ë°˜ìœ¼ë¡œ RAG ë¬¸ì„œì—ì„œ artist, period, webpage ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜.
    """
    art_database = load_art_database()
    
    for entry in art_database:
        if entry["title"].lower() == title.lower():  # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë¹„êµ
            return {
                "artist": entry["artist_display_name"],
                "period": entry["period"],
                "webpage": entry["webpage"]
            }
    
    # í•´ë‹¹ ì‘í’ˆì´ ì—†ì„ ê²½ìš° Untitledë¡œ ì²˜ë¦¬
    return None

########################### SETP 2 : VLM (Vision to LLM) #####################################

import re

def clean_and_restore_spacing(text, prompt):
    """
    VLM(Qwen2.5-VL) ì¶œë ¥ì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ ê²¹ì¹˜ëŠ” ë¶€ë¶„ì„ ìë™ ê°ì§€í•˜ì—¬ ì œê±°í•˜ëŠ” í•¨ìˆ˜.
    """
    # âœ… 1. í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ í¬í•¨í•˜ëŠ” ë¶€ë¶„ ì œê±°
    prompt = prompt.strip()  # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()  # ì•ë’¤ ê³µë°± ì œê±°

    # âœ… 2. í”„ë¡¬í”„íŠ¸ì™€ ì¶œë ¥ì´ ê²¹ì¹˜ëŠ” ê²½ìš° ì‚­ì œ
    if prompt in text:
        text = text.replace(prompt, "").strip()

    # âœ… 3. "system", "You are a helpful assistant." ê°™ì€ AI ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì œê±°
    text = re.sub(r"(system|You are a helpful assistant\.|user)", "", text, flags=re.IGNORECASE)

    # âœ… 4. "assistant" ê°™ì€ ì‘ë‹µ íƒœê·¸ ì œê±° (ex: "assistant 1. ì£¼ìš” ê°ì²´")
    text = re.sub(r"assistant\s*\d*\.*", "", text, flags=re.IGNORECASE)

    # âœ… 5. ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = re.sub(r"\s+", " ", text).strip()

    # âœ… 6. ë¶ˆí•„ìš”í•œ ê¸°í˜¸(-, *, â€¢) ì •ë¦¬ (ì¼ê´€ë˜ê²Œ "-" ì‚¬ìš©)
    text = re.sub(r"[â€¢*]", "-", text)

    # âœ… 7. í•œê¸€ê³¼ ì˜ì–´/ìˆ«ì ì‚¬ì´ ë„ì–´ì“°ê¸° ë³µì›
    text = re.sub(r"([ê°€-í£])([a-zA-Z0-9])", r"\1 \2", text)  # í•œê¸€ + ì˜ì–´/ìˆ«ì
    text = re.sub(r"([a-zA-Z0-9])([ê°€-í£])", r"\1 \2", text)  # ì˜ì–´/ìˆ«ì + í•œê¸€

    return text


# ì´ë¯¸ì§€ ì„¤ëª… VLM
def generate_vlm_description_qwen(image): # inputì´ ì´ë¯¸ì§€ë¡œ ì•Œê³  ìˆì–´ì„œ imageë¡œ ë°”ê¿ˆ.
    # âœ… ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì§• (512x512)
    # ë§Œì•½ image_pathê°€ numpy ë°°ì—´ì´ë¼ë©´:
    if isinstance(image, np.ndarray):
        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) # ì´ë¯¸ì§€ ë°›ì„ ë•Œ ì²˜ë¦¬.
    else:
        image = Image.open(image).convert("RGB") # ë§Œì•½ ê²½ë¡œê°€ ë“¤ì–´ì˜¤ë©´ ê·¸ë•Œ ì²˜ë¦¬.
    image = image.resize((512, 512)) # ì¼ë‹¨ì€ í¬ê¸° ì •ê·œí™” í–ˆëŠ”ë° ì¶”í›„ ìˆ˜ì • í•„ìš”.
    
    prompt = """
    ì´ ê·¸ë¦¼ì„ ë³´ê³  ì¥ë©´ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.  
    ë‹¨ìˆœí•œ í‚¤ì›Œë“œê°€ ì•„ë‹ˆë¼, ì‹¤ì œë¡œ ë³´ê³  ì´ì•¼ê¸°í•˜ë“¯ì´ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.  
    ê° ìš”ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ë‚˜ì—´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì „ì²´ì ì¸ ì¥ë©´ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.  

    - ì–´ë–¤ ì‚¬ë¬¼ì´ ê°€ì¥ ëˆˆì— ë„ë‚˜ìš”?  
    - ì‚¬ëŒë“¤ì€ ë¬´ì—‡ì„ í•˜ê³  ìˆë‚˜ìš”?  
    - ìƒ‰ìƒê³¼ ë¹›ì˜ íë¦„ì€ ì–´ë–¤ ëŠë‚Œì„ ì£¼ë‚˜ìš”?  
    - ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ëŠ” ì–´ë–»ê²Œ í‘œí˜„ë  ìˆ˜ ìˆë‚˜ìš”?  

    ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ 2~3ë¬¸ì¥ ì •ë„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
    ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€(ê°€-í£)ê³¼ ì˜ì–´(a-z)ë§Œ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**
    âš ï¸ **í•œì(æ¼¢å­—)ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.** âš ï¸  
    í•œìê°€ í¬í•¨ë  ê²½ìš°, ë‹¤ì‹œ í•œê¸€ê³¼ ì˜ì–´ë¡œë§Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    """


    # âœ… ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (apply_chat_template ì‚¬ìš©)
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {"type": "text", "text": prompt},
            ],
        }
    ]

    # âœ… Chat Template ì ìš© (Qwen2.5-VLì—ì„œëŠ” í•„ìˆ˜)
    text_input = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) # ì´ê±° ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì•ˆëŒì•„ê°‘ë‹ˆë‹¤ ì§„ì§œ ì¤‘ìš”í•¨

    # âœ… ëª¨ë¸ ì…ë ¥ ë³€í™˜
    inputs = processor(
        text=[text_input],  # âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì…ë ¥
        images=image,
        return_tensors="pt",
        padding=True,
    ).to(model.device)

    # âœ… ëª¨ë¸ ì‹¤í–‰ (í† í° ìˆ˜ ìµœì í™”)
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=256) # 128ë¡œ í•˜ë‹ˆê¹Œ ì¢€ ì§¤ë¦¬ëŠ”ë“¯;

    # âœ… ê²°ê³¼ ë””ì½”ë”© ë° ì„¸ë¡œ ì¶œë ¥ ë¬¸ì œ í•´ê²°
    description = processor.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]
    description = clean_and_restore_spacing(description, prompt) # í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ì•¼ ì •ì œ ê°€ëŠ¥.

    return description


########################### STEP 3 : (VLMê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ) LLM ###############################
from gtts import gTTS

def generate_rich_description(title, vlm_desc, dominant_colors, edges):
    """
    AIê°€ ìƒì„±í•œ ê¸°ë³¸ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ë³´ë‹¤ í’ë¶€í•œ ê·¸ë¦¼ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    CNNì´ ì¸ì‹í•œ ì‘í’ˆì´ë©´ RAG ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê³ , ì¸ì‹í•˜ì§€ ëª»í•˜ë©´ ì‹œê°ì  ìš”ì†Œë§Œ ì‚¬ìš©.
    """

    # ğŸ”¹ 1. RAGì—ì„œ ì‘í’ˆ ì •ë³´ ê²€ìƒ‰
    artwork_info = search_artwork_by_title(title)

    # ğŸ”¹ 2. CNNì´ ì‘í’ˆì„ ì¸ì‹í•˜ì§€ ëª»í•œ ê²½ìš° (Untitled ì²˜ë¦¬)
    if not artwork_info:
        print("ğŸ¨ CNNì´ ì‘í’ˆì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‹œê°ì  ì •ë³´ë§Œ í™œìš©í•©ë‹ˆë‹¤.")
        color_names = [get_color_name(c) for c in dominant_colors[:5]]
        dominant_colors_text = ", ".join(color_names)
        edges_detected = edges #= "ëª…í™•íˆ íƒì§€ë¨" if np.sum(edges) > 10000 else "ë¶ˆëª…í™•í•˜ê²Œ íƒì§€ë¨"

        prompt_template = PromptTemplate(
            input_variables=["vlm_desc", "dominant_colors", "edges_detected"],
            template="""
            ì´ ê·¸ë¦¼ì„ ë³´ë©´ ì–´ë–¤ ëŠë‚Œì´ ë“œë‚˜ìš”?  
            ìƒ‰ê°ê³¼ ë¶„ìœ„ê¸°ê°€ ì–´ë–¤ ì¸ìƒì„ ì£¼ëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.  

            - ê·¸ë¦¼ì„ ë³´ë©´ {vlm_desc} ê°™ì€ íŠ¹ì§•ì´ ìˆì–´ìš”.  
            - ìƒ‰ê°ì€ {dominant_colors} ê³„ì—´ì´ ì£¼ë¥¼ ì´ë£¨ê³  ìˆì–´ìš”.  
            - ë¹›ì˜ íë¦„ì„ ë³´ë©´ {edges_detected} ëŠë‚Œì´ì—ìš”.  

            ë„ˆë¬´ ë”±ë”±í•œ ì„¤ëª…ë³´ë‹¤ëŠ”, ì¹œêµ¬ì—ê²Œ ê·¸ë¦¼ì„ ì†Œê°œí•˜ëŠ” ëŠë‚Œìœ¼ë¡œ  
            ê°ì„±ì ì´ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì•¼ê¸°í•´ ì£¼ì„¸ìš”.  
            200~300ì ì •ë„ë¡œ ê°„ê²°í•˜ë©´ì„œë„ í’ë¶€í•˜ê²Œ í‘œí˜„í•´ ì£¼ì„¸ìš”.
            ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€(ê°€-í£)ê³¼ ì˜ì–´(a-z)ë§Œ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**
            ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì, í•œìëŠ” í¬í•¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
            """
        )

        formatted_prompt = prompt_template.format(
            vlm_desc=vlm_desc,
            dominant_colors=dominant_colors_text,
            edges_detected=edges_detected
        )

        completion = client.chat.completions.create(
            model="qwen-2.5-32b",
            messages=[{"role": "user", "content": formatted_prompt}],
            temperature=0.5,
            max_tokens=512,
            top_p=0.95
        )

        return completion.choices[0].message.content.strip()
    
    # âœ… Fix: ìƒ‰ìƒ ì¤‘ë³µ ì œê±°
    color_names = [get_color_name(c) for c in dominant_colors[:5]]
    unique_colors = list(dict.fromkeys([color.strip() for name in color_names for color in name.split(',')]))
    colors_text = ", ".join(unique_colors)

    # ğŸ”¹ 3. ì‘í’ˆì„ ì¸ì‹í•œ ê²½ìš° (RAG ì •ë³´ í™œìš©)
    prompt_variables = {
        "title": title,
        "artist": "Unidentified Artist", # ì¼ë‹¨ ì‘ì ë¯¸ìƒ.
        "vlm_desc": vlm_desc,
        "dominant_colors": colors_text,
        #"edges_detected": "ëª…í™•íˆ íƒì§€ë¨" if np.sum(edges) > 10000 else "ë¶ˆëª…í™•í•˜ê²Œ íƒì§€ë¨"
    }

    if artwork_info:
        artist = artwork_info.get("artist")
        
        title_translations, artist_translations = translate.create_translation_mappings(title, artist)
        
        if title_translations:
            prompt_variables["title"] = title_translations
        if artist_translations:
            prompt_variables["artist"] = artist_translations
            
    if artwork_info.get("period"):
        prompt_variables["correct_period"] = artwork_info["period"]
    if artwork_info.get("webpage"):
        prompt_variables["webpage"] = artwork_info["webpage"]

    # ğŸ”¹ 4. PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ë™ì  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    # âœ… Prompt Templateì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_template = PromptTemplate(
        input_variables=list(prompt_variables.keys()),
        template="""
        {title}ê³¼(ì™€) {artist}ì— ê´€í•œ ì •ë³´ë§Œ ê²€ìƒ‰í•˜ì„¸ìš”. ìƒ‰ìƒëª…({dominant_colors})ì€ ì •í™•íˆ ì£¼ì–´ì§„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        
        "{title}"ë¼ëŠ” ì‘í’ˆì„ ê°ìƒí•˜ê³  ìˆì–´ìš”.  
        ì´ ì‘í’ˆì€ {artist}ì´(ê°€) {correct_period} ì‹œê¸°ì— ì œì‘í•œ ì‘í’ˆì´ì—ìš”.  

        - ê·¸ë¦¼ì„ ë³´ë©´ {vlm_desc} ê°™ì€ íŠ¹ì§•ì´ ìˆì–´ìš”.  
        - ìƒ‰ê°ì€ {dominant_colors} ê³„ì—´ì´ ì£¼ë¥¼ ì´ë£¨ê³  ìˆì–´ìš”. ìƒ‰ìƒ ì´ë¦„ì€ ì •í™•íˆ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
        
        ì´ ì‘í’ˆì˜ ë¶„ìœ„ê¸°ì™€ ì—­ì‚¬ì  ì˜ë¯¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.  
        ë„ˆë¬´ í•™ë¬¸ì ì¸ ì„¤ëª…ë³´ë‹¤ëŠ”, í¸ì•ˆí•œ ëŒ€í™”ì²˜ëŸ¼ í‘œí˜„í•´ ì£¼ì„¸ìš”.
        200~300ì ì •ë„ë¡œ ê°„ê²°í•˜ê³  ê°ì„±ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        ì„¤ëª…ì€ ë°˜ë“œì‹œ **í•œê¸€(ê°€-í£)ê³¼ ì˜ì–´(a-z)ë§Œ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**
        ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì, í•œìëŠ” í¬í•¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  

        {webpage}
        """
    )

    # `None`ì´ í¬í•¨ëœ key ì œê±°
    filtered_prompt_variables = {k: v for k, v in prompt_variables.items() if v is not None}

    formatted_prompt = prompt_template.format(**filtered_prompt_variables)

    completion = client.chat.completions.create(
        model="qwen-2.5-32b",
        messages=[{"role": "user", "content": formatted_prompt}],
        temperature=0.5,
        max_tokens=512,
        top_p=0.95
    )

    return completion.choices[0].message.content.strip()

def text_to_speech(text, output_file="output.mp3"):
    """
    ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„± íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    """
    try:
        if "<think>" in text:
            text = text.split("</think>")[-1].strip()
        tts = gTTS(text=text, lang='ko')
        tts.save(output_file)
        print(f"ìŒì„± íŒŒì¼ì´ '{output_file}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        os.system(f"start {output_file}")  # Windows (macOS: open, Linux: xdg-open)
    except Exception as e:
        print(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
########################### STEP 5 : ëŒ€í™” ëª¨ë“œë¥¼ ì§„í–‰í•˜ëŠ” í•¨ìˆ˜ ###############################
# 1. RAG
# 1-1. VTS ì§ˆë¬¸ì§€ RAGì—ì„œ ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì˜ˆì‹œ) : VTS_RAG_questions.json

# âœ… 1. ë¬¸ì¥ ìœ ì‚¬ë„ ë¶„ì„ì„ ìœ„í•œ ëª¨ë¸ ë¡œë“œ (KoBERT ì‚¬ìš©)
embedding_model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")

def load_vts_questions():
    """VTS ì§ˆë¬¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜"""
    current_dir = os.path.dirname(os.path.abspath(__file__))  
    file_path = os.path.join(current_dir, "data", "VTS_RAG_questions.json")

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"âŒ VTS ì§ˆë¬¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)
    
# âœ… ì‚¬ìš©ìì˜ ì…ë ¥ ìœ í˜• ë¶„ì„ (ì‘í’ˆ ì •ë³´ ìš”êµ¬ vs ê°ìƒ í‘œí˜„)
def classify_user_input(user_input):
    """
    ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì‘í’ˆ ì„¤ëª…ì„ ìš”êµ¬í•˜ëŠ”ì§€(1-1) vs ìì‹ ì˜ ê°ìƒì„ ë§í•˜ëŠ”ì§€(1-2) ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜.
    """
    keywords_info = ["ì´ ì‘í’ˆ", "ì„¤ëª…", "ë°°ê²½", "ì‘ê°€", "ì˜ë¯¸", "ë‹¹ì‹œ ìƒí™©"]
    keywords_feeling = ["ëŠë‚Œ", "ë¶„ìœ„ê¸°", "ì¸ìƒì ", "ë§ˆìŒì— ë“¤ì–´", "ìƒê°", "ì˜ê²¬"]

    if any(keyword in user_input for keyword in keywords_info):
        return "info"  # ì‘í’ˆ ì„¤ëª… ìš”ì²­ (1-1)
    elif any(keyword in user_input for keyword in keywords_feeling):
        return "feeling"  # ê°ìƒ í‘œí˜„ (1-2)
    return "unknown"


# âœ… 2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (LLM í™œìš©)
def answer_user_question(user_response, conversation_history, title, artist, rich_description):
    
    # ğŸ”¹ ëŒ€í™” ë§¥ë½ ì •ë¦¬
    context = "\n".join(conversation_history[-3:])  # ìµœê·¼ 3ê°œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ìµœì í™”)
    
    conversation_history.append(f"ì‚¬ìš©ì: {user_response}")

    prompt = f"""
            ì‚¬ìš©ìëŠ” '{artist}'ì˜ '{title}' ì‘í’ˆì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.
            ì´ì „ ëŒ€í™” : 
            {context}
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ : 
            "{user_response}"
            
            ì‘í’ˆ ì„¤ëª… : "{rich_description}"
            ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{user_response}"
            
            ìœ„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„¸í•˜ê³  ìœ ìµí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
            """

    completion = client.chat.completions.create(
        model="qwen-2.5-coder-32b",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
        max_tokens=256,
        top_p=0.95
    )
    
    return completion.choices[0].message.content.strip()
        

# âœ… 3. ì‚¬ìš©ìì˜ ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ VTS ì§ˆë¬¸ ì¶”ì²œ
def recommend_vts_question(user_response, previous_questions):
    """ì‚¬ìš©ìì˜ ì‘ë‹µê³¼ ê°€ì¥ ê´€ë ¨ì´ ê¹Šì€ VTS ì§ˆë¬¸ì„ ì¶”ì²œí•˜ëŠ” í•¨ìˆ˜"""
    vts_questions = load_vts_questions()

    # ì´ë¯¸ ì‚¬ìš©í•œ ì§ˆë¬¸ ì œì™¸
    available_questions = [q for q in vts_questions if q["question"] not in previous_questions]

    # ë¬¸ì¥ ì„ë² ë”© ìƒì„±
    user_embedding = embedding_model.encode(user_response, convert_to_tensor=True)
    question_embeddings = embedding_model.encode([q["question"] for q in available_questions], convert_to_tensor=True)

    # ìœ ì‚¬ë„ ê³„ì‚°
    similarities = util.pytorch_cos_sim(user_embedding, question_embeddings)[0]
    best_match_idx = similarities.argmax().item()

    return available_questions[best_match_idx]["question"]


# âœ… LLMì„ í™œìš©í•œ VTS ë°˜ì‘ ë° ì§ˆë¬¸ ìƒì„±
def generate_vts_response(user_input, conversation_history):
    """
    ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ë°˜ì‘ê³¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    """
    # ğŸ”¹ ëŒ€í™” ë§¥ë½ ì •ë¦¬
    context = "\n".join(conversation_history[-3:])  # ìµœê·¼ 3ê°œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ìµœì í™”)

    prompt = f"""
    ì‚¬ìš©ìê°€ ë¯¸ìˆ  ì‘í’ˆì„ ê°ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ì´ì „ ëŒ€í™”:
    {context}

    ì‚¬ìš©ìì˜ ì…ë ¥:
    "{user_input}"

    AIì˜ ì—­í• :
    1. ì‚¬ìš©ìì˜ ê°ìƒì— ëŒ€í•´ ì ì ˆí•œ ë°˜ì‘ì„ ì œê³µí•©ë‹ˆë‹¤.
    2. ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„±í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°‘ë‹ˆë‹¤.

    AIì˜ ì‘ë‹µ í˜•ì‹:
    1. ë°˜ì‘: (ì‚¬ìš©ìì˜ ê°ìƒì„ ë°˜ì˜í•œ í”¼ë“œë°±)
    2. ì§ˆë¬¸: (VTS ê¸°ë°˜ì˜ ì ì ˆí•œ ì¶”ê°€ ì§ˆë¬¸)
    """

    completion = client.chat.completions.create(
        model="qwen-2.5-coder-32b",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
        max_tokens=256,
        top_p=0.95
    )

    response = completion.choices[0].message.content.strip()
    
    # ğŸ”¹ ì‘ë‹µì„ "ë°˜ì‘ + ì§ˆë¬¸"ìœ¼ë¡œ ë¶„ë¦¬
    try:
        response_parts = response.split("\n")
        reaction = response_parts[0].strip() if response_parts else "í¥ë¯¸ë¡œìš´ ìƒê°ì´ì—ìš”."
        question = response_parts[1].strip() if len(response_parts) > 1 else "ì´ ì‘í’ˆì„ ë³´ê³  ì–´ë–¤ ì ì´ ê°€ì¥ ì¸ìƒì ì´ì—ˆë‚˜ìš”?"
    except:
        reaction, question = response, "ì´ ì‘í’ˆì„ ë³´ê³  ì–´ë–¤ ì ì´ ê°€ì¥ ì¸ìƒì ì´ì—ˆë‚˜ìš”?"

    return reaction, question


# âœ… VTS ê°ìƒ ëŒ€í™” íë¦„ (í”¼ë“œë°± + ì§ˆë¬¸ ì¡°í•©)
def start_vts_conversation(title, rich_description, dominant_colors, edges):
    """VTS ê¸°ë°˜ ê°ìƒ ëŒ€í™” ì§„í–‰ í•¨ìˆ˜"""
    print("\nğŸ–¼ï¸ VTS ê°ìƒ ëª¨ë“œ ì‹œì‘!")

    conversation_history = []  # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
    user_response = input("ğŸ¨ ì‘í’ˆì„ ë³´ê³  ë– ì˜¤ë¥¸ ëŠë‚Œì´ë‚˜ ê¶ê¸ˆí•œ ì ì„ ë§í•´ì£¼ì„¸ìš” (ì¢…ë£Œ: exit): ")
    
    artwork_info = search_artwork_by_title(title)
    
    if artwork_info:
        artist = artwork_info.get("artist")
        
        title_translations, artist_translations = translate.create_translation_mappings(title, artist)
        title, artist = title_translations, artist_translations

    while user_response.lower() != "exit":
        
        # ì§ˆë¬¸ ë‹µë³€ ì¢…ë¥˜ í™•ì¸
        input_type = classify_user_input(user_response)
        
        if input_type == "info":
            # ğŸ”¹ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append(f"ì‚¬ìš©ì: {user_response}")
            
            answer = answer_user_question(user_response, conversation_history, title, rich_description, dominant_colors)
            
            conversation_history.append(f"AI: {answer}")
            
            print("\n[ì •ë³´ ë‹µë³€]")
            print(answer)
            
            user_response = input(f"ğŸ¨ í˜¹ì‹œ ë” ê¶ê¸ˆí•˜ì‹ ê²Œ ìˆìœ¼ì‹ ê°€ìš”? (ì¢…ë£Œ: exit): ")
        
        elif input_type == "feeling":
            # ğŸ”¹ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append(f"ì‚¬ìš©ì: {user_response}")

            # ğŸ”¹ AI ë°˜ì‘ ë° ì§ˆë¬¸ ìƒì„±
            reaction, next_question = generate_vts_response(user_response, conversation_history)

            # ğŸ”¹ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append(f"AI: {reaction}")
            conversation_history.append(f"AI ì§ˆë¬¸: {next_question}")

            # ğŸ”¹ í”¼ë“œë°± ë° ë‹¤ìŒ ì§ˆë¬¸ ì¶œë ¥
            print(f"\nğŸ’¬ {reaction}")
            user_response = input(f"ğŸ¨ {next_question} (ì¢…ë£Œ: exit): ")

    print("ğŸ“¢ VTS ê°ìƒ ëª¨ë“œ ì¢…ë£Œ.")